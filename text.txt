__global__ void calculateMatrixProduct(int ny, int nx, int nn, float* result, float* d) {
    int ia = threadIdx.x;
    int ja = threadIdx.y;
    int ic = blockIdx.x;
    int jc = blockIdx.y;

    if (jc < ic) {
        return;
    }

    float v[8][8];
    for (int ib = 0; ib < 8; ++ib) {
        for (int jb = 0; jb < 8; ++jb) {
            v[ib][jb] = 0;
        }
    }
    for (int k = 0; k < nx; ++k) {
        float x[8];
        float y[8];
        for (int ib = 0; ib < 8; ++ib) {
            int i = ic * 64 + ib * 8 + ia;
            x[ib] = d[nn*k + i];
        }
        for (int jb = 0; jb < 8; ++jb) {
            int j = jc * 64 + jb * 8 + ja;
            y[jb] = d[nn*k + j];
        }
        for (int ib = 0; ib < 8; ++ib) {
            for (int jb = 0; jb < 8; ++jb) {
                v[ib][jb] += x[ib]*y[jb];
            }
        }
    }
    for (int ib = 0; ib < 8; ++ib) {
        for (int jb = 0; jb < 8; ++jb) {
            int i = ic * 64 + ib * 8 + ia;
            int j = jc * 64 + jb * 8 + ja;
            if (i < ny && j < ny) {
                result[ny*i + j] = v[ib][jb];
            }
        }
    }
}
__global__ void calculateMatrixProductPp(int ny, int nx, int nn, float* paddedData, float* tempData) {
    int ja = threadIdx.x;
    int i = blockIdx.y;


    for (int jb = 0; jb < nn; jb += 64) {
        int j = jb + ja;
        float v = (j < ny && i < nx) ? tempData[nx*j + i] : 0;
        paddedData[nn*i + j] = v;

    }
}

int lol() {
    int nn = roundup(ny, 64);
    // Allocate memory & copy data to GPU

    float* resultCuda = NULL;
    CHECK(cudaMalloc((void**)&resultCuda, ny * ny * sizeof(float)));
    float* tempCuda = NULL;
    CHECK(cudaMalloc((void**)&tempCuda, ny * nx * sizeof(float)));
    float* paddedData = NULL;
    CHECK(cudaMalloc((void**)&paddedData, nx * nn * sizeof(float)));

    CHECK(cudaMemcpy(tempCuda, &temp[0], ny * nx * sizeof(float), cudaMemcpyHostToDevice));

    // Run kernel
    {
        dim3 dimBlock(64, 1); //dim3 dimBlock(64, 1);
        dim3 dimGrid(1, nx);
        calculateMatrixProductPp<<<dimGrid, dimBlock>>>(ny, nx, nn, paddedData, tempCuda);
        CHECK(cudaGetLastError());
    }

    // Run kernel
    {
        dim3 dimBlock(8, 8);
        dim3 dimGrid(divup(ny, 64), divup(ny, 64));
        calculateMatrixProduct<<<dimGrid, dimBlock>>>(ny, nx, nn, resultCuda, paddedData);
        CHECK(cudaGetLastError());
    }

    // Copy data back to CPU & release memory
    CHECK(cudaMemcpy(result, resultCuda, ny * ny * sizeof(float), cudaMemcpyDeviceToHost));
    CHECK(cudaFree(resultCuda));
    CHECK(cudaFree(tempCuda));
}
